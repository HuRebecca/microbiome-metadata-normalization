{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[new_col] = df.apply(lambda x: True if x[col_name] else False, axis = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qiita Fecal Metadata Normalization \n",
    "#### by Rebecca Hu\n",
    "#### 02/21/2019\n",
    "rows:  40763 cols:  2570\n",
    "### Added column headers include:\n",
    "qiita_host_age - normalized age in years\n",
    "<br> qiita_host_age_units - 'years' repeated in all rows\n",
    "<br> qiita_host_sex - normalized sex as 'male' or 'female'\n",
    "<br> qiita_host_ethnicity_white - True if the host identifies as white, False or Nan otherwise\n",
    "<br> qiita_host_ethnicity_black_or_african_american - True if the host identifies as black or African American, False or Nan otherwise\n",
    "<br> qiita_host_ethnicity_hispanic_or_latino - True if the host identifies as hispanic or latino, False or Nan otherwise\n",
    "<br> qiita_host_ethnicity_asian - True if the host identifies as asian, False or Nan otherwise\n",
    "<br> qiita_host_ethnicity_american_indian_or_alaska_native - True if the host identifies as Native American, False or Nan otherwise\n",
    "<br> qiita_host_ethnicity_native_hawaiian_or_other_pacific_islander - True if the host identifies as native Hawaiian or Pacific Islander, False or Nan otherwise\n",
    "<br> qiita_host_ethnicity_other - True if host specified 'other' as ethnicity/race, False or Nan otherwise\n",
    "<br> qiita_host_ethnicity_multiracial - True if host specified 'multi' or some variation as ethnicity/race, False or Nan otherwise\n",
    "<br> qiita_host_multiracial - True if host specified multiple ethinicies/races, False or Nan otherwise\n",
    "<br> qiita_host_ethnicity_combined - string values, most specific host race/ethinicity e.g. 'Japanese-Caucasian'\n",
    "<br> qiita_host_weight - normalized & cleaned weight in kg\n",
    "<br> qiita_host_weight_units - 'kg' repeated in all rows\n",
    "<br> qiita_host_height - normalized and cleaned weight in cm\n",
    "<br> qiita_host_height_units - 'cm' repeated in all rows\n",
    "<br> qiita_host_bmi - float values, normalized host bmi\n",
    "<br> qiita_host_healthy_weight - True if host falls under healthy weight category, False or Nan otherwise\n",
    "<br> qiita_host_food_allergy - True if host has food allergy \n",
    "<br> qiita_host_allergy - True if host has any allergies in allergy dictionaries, False or Nan otherwise\n",
    "<br> qiita_host_cancer - True if host has any cancer in cancer dictionary, False or Nan otherwise\n",
    "<br> qiita_host_ibd - True if host has inflammatory bowel disease, False or Nan otherwise\n",
    "<br> qiita_host_ibd_type - 'cd' if host has Crohn's Disease, 'uc' if host has ulcerative colitis, 'not specified' if host has ibd but does not specify what kind, 'not applicable' if host does not have ibd\n",
    "<br> qiita_host_diabetes - True if host has diabetes, False otherwise\n",
    "<br> qiita_host_diabetes_subtype - 'type1' if host has Type I diabetes, 'type2' is host has Type II diabetes, 'not specified' if host has diabetes but does not specify what kind, 'not applicable' if host does not have diabetes\n",
    "<br> qiita_host_disease - True if host has a miscellaneous disease in disease dictionary, False otherwise\n",
    "<br> qiita_host_medication - True if host reported taking any medications, False otherwise\n",
    "<br> qiita_host_healthy - False if host has any disease, allergy, or uses medication, True otherwise\n",
    "#### Static Columns\n",
    "qiita_sample_type - 'stool' repeated in all rows\n",
    "<br> qiita_empo_1 - 'host-associated' repeated in all rows\n",
    "<br> qiita_empo_2 - 'animal' repeated in all rows\n",
    "<br> qiita_empo_3 - 'animal distal gut' repeated in all rows\n",
    "<br> qiita_host_scientific_name - 'Homo sapiens' repeated in all rows\n",
    "<br> qiita_host_taxid - 9606 repeated in all rows\n",
    "<br> qiita_host_common_name - 'human' repeated in all rows\n",
    "<br> qiita_env_feature - 'human-associated habitat' repeated in all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains(string):\n",
    "    '''\n",
    "    a function to check if there are any columns names in df that contain \"string\"\n",
    "    \n",
    "    param: any string that you are looking for within the column header\n",
    "    \n",
    "    return: a list of column headers in df that contain the inputter string\n",
    "    '''\n",
    "    return df.columns[df.columns.str.contains(str(string))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_csv(file):\n",
    "    '''\n",
    "    reads in the csv and normalizes all variations of true and false values to bool and all variations of null values to nan\n",
    "    \n",
    "    param: the filename of the csv as a string\n",
    "    return: cleaned pandas DataFrame\n",
    "    '''\n",
    "    df = pd.read_csv(file,header=0, sep ='\\t', decimal = ',',\n",
    "            true_values =['true','yes','y','Yes','Y','YES', 'Self-diagnosed', 'Diagnosed by a medical professional (doctor, physician assistant)'],\n",
    "            false_values=['false','no','n','No','N','NO', 'I do not have this condition', 'I do not have this condition'],\n",
    "            na_values=['Unknown','Unspecified','no_data','not applicable', 'Not applicable' ,'Missing: not collected', 'Missing: not provided',\n",
    "                      'Missing: Not recorded', 'Missing: Restricted access' , 'Missing', 'Not provided', 'unspecified', 'MISSING: RESTRICTED ACCESS',\n",
    "                      'not collected', 'not provided', 'missing: not provided', 'MIssing: Not provided', 'Missing: Not reported'],\n",
    "            low_memory= False\n",
    "            )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows:  40763 cols:  2570\n"
     ]
    }
   ],
   "source": [
    "#Read Fecal Metadata file\n",
    "df = clean_csv('20190223_all_human_fecal_metadata.txt')\n",
    "num_row = df.shape[0]\n",
    "num_col = df.shape[1]\n",
    "print('rows: ', num_row, 'cols: ', num_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#SampleID</th>\n",
       "      <th>aborh</th>\n",
       "      <th>achilles_tendinitis</th>\n",
       "      <th>acid_reflux</th>\n",
       "      <th>acne</th>\n",
       "      <th>acne_medication</th>\n",
       "      <th>acne_medication_otc</th>\n",
       "      <th>active_disease</th>\n",
       "      <th>activity_target</th>\n",
       "      <th>acute_kidney_failure</th>\n",
       "      <th>...</th>\n",
       "      <th>years_known_subject</th>\n",
       "      <th>years_smoker</th>\n",
       "      <th>yellow_rice_wine</th>\n",
       "      <th>ygrt</th>\n",
       "      <th>ygrt_freq</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>yogurt_brand</th>\n",
       "      <th>yogurt_live_culture</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>zygosity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11669.St.chronic.GLD019.T.60388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10352.MIC20100111.57838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11405.subject631.timepoint0.60671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10317.000022608.56754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11358.2353.61922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2570 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           #SampleID aborh achilles_tendinitis acid_reflux  \\\n",
       "0    11669.St.chronic.GLD019.T.60388   NaN                 NaN         NaN   \n",
       "1            10352.MIC20100111.57838   NaN                 NaN         NaN   \n",
       "2  11405.subject631.timepoint0.60671   NaN                 NaN         NaN   \n",
       "3              10317.000022608.56754   NaN                 NaN         NaN   \n",
       "4                   11358.2353.61922   NaN                 NaN         NaN   \n",
       "\n",
       "  acne acne_medication acne_medication_otc active_disease activity_target  \\\n",
       "0  NaN             NaN                 NaN            NaN             NaN   \n",
       "1  NaN             NaN                 NaN            NaN             NaN   \n",
       "2  NaN             NaN                 NaN            NaN             NaN   \n",
       "3  NaN            True               False            NaN             NaN   \n",
       "4  NaN             NaN                 NaN            NaN             NaN   \n",
       "\n",
       "  acute_kidney_failure   ...    years_known_subject years_smoker  \\\n",
       "0                  NaN   ...                    NaN          NaN   \n",
       "1                  NaN   ...                    NaN          NaN   \n",
       "2                  NaN   ...                    NaN          NaN   \n",
       "3                  NaN   ...                    NaN          NaN   \n",
       "4                  NaN   ...                    NaN          NaN   \n",
       "\n",
       "  yellow_rice_wine ygrt ygrt_freq yogurt yogurt_brand yogurt_live_culture  \\\n",
       "0              NaN  NaN       NaN    NaN          NaN                 NaN   \n",
       "1              NaN  NaN       NaN    NaN          NaN                 NaN   \n",
       "2              NaN  NaN       NaN    NaN          NaN                 NaN   \n",
       "3              NaN  NaN       NaN    NaN          NaN                 NaN   \n",
       "4              NaN  NaN       NaN    NaN          NaN                 NaN   \n",
       "\n",
       "  zipcode zygosity  \n",
       "0     NaN      NaN  \n",
       "1     NaN      NaN  \n",
       "2     NaN      NaN  \n",
       "3     NaN      NaN  \n",
       "4     NaN      NaN  \n",
       "\n",
       "[5 rows x 2570 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display all column headers in the DataFrame\n",
    "\n",
    "#pd.options.display.max_seq_items = 3000\n",
    "#df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optmized (using iterows) function to normalize ages and compile them into a list\n",
    "def normalize_age(df):\n",
    "    '''\n",
    "    normalize age columns into years and compile them into a Series\n",
    "    \n",
    "    param: DataFrame containing all different age columns\n",
    "    return: a Series containing all normalized age values\n",
    "    '''\n",
    "    age_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        if not math.isnan(float(row['age'])):\n",
    "            \n",
    "            if row['age_unit'] == 'years' or  row['age_units'] == 'years':\n",
    "                age_list.append(round(float(row['age']), 3))\n",
    "                \n",
    "            elif row['age_unit'] == 'weeks' or  row['age_units'] == 'weeks':\n",
    "                normalized_age = float(row['age']) / 52\n",
    "                age_list.append(round(normalized_age, 3))\n",
    "                \n",
    "            elif row['age_unit'] == 'days' or  row['age_units'] == 'days':\n",
    "                normalized_age = float(row['age']) / 365\n",
    "                age_list.append(round(normalized_age, 3))\n",
    "                \n",
    "            elif row['age_unit'] == 'minutes' or  row['age_units'] == 'minutes':\n",
    "                normalized_age = float(row['age']) / 525600\n",
    "                age_list.append(round(normalized_age, 3))\n",
    "                \n",
    "            else:\n",
    "                age_list.append(float('Nan'))\n",
    "                \n",
    "        elif not math.isnan(float(row['age_baby_days'])):\n",
    "            normalized_age = float(row['age_baby_days']) / 365\n",
    "            age_list.append(round(normalized_age, 3))\n",
    "            \n",
    "        elif not math.isnan(float(row['age_corrected'])):\n",
    "            age_list.append(round(float(row['age_corrected']), 3)) \n",
    "            \n",
    "        elif not math.isnan(float(row['age_in_years'])):\n",
    "            age_list.append(round(float(row['age_in_years']), 3))\n",
    "        \n",
    "        elif not math.isnan(float(row['age_years'])):\n",
    "            age_list.append(round(float(row['age_years']), 3))\n",
    "            \n",
    "        elif not math.isnan(float(row['host_age'])):\n",
    "            age_list.append(round(float(row['host_age']), 3))            \n",
    "        \n",
    "        else:\n",
    "            age_list.append(float('Nan'))\n",
    "            \n",
    "    return pd.Series(age_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.4 s ± 207 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "#qiita_host_age column \n",
    "df['qiita_host_age']= normalize_age(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% result\n",
    "# 11.4 s ± 207 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_age_units column ('years' in all rows)\n",
    "age_units = ['years']\n",
    "age_units_list = [] \n",
    "\n",
    "for i in range(0, num_row):\n",
    "    age_units_list += age_units\n",
    "    \n",
    "df['qiita_host_age_units'] = pd.Series(age_units_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sex(df):\n",
    "    '''\n",
    "    normalizes sex and gender into 'male' or 'female'\n",
    "    \n",
    "    param: DataFrame containing all sex/gender columns\n",
    "    return: pd.Series containing all normalized sex \n",
    "    '''\n",
    "    sex_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        if row['gender'] == 'male' or row['gender'] == 'female':\n",
    "            sex_list.append(row['gender'])\n",
    "        elif row['sex'] == 'male' or row['sex'] == 'female':\n",
    "            sex_list.append(row['sex'])\n",
    "        else:\n",
    "            sex_list.append(float('Nan'))\n",
    "    return pd.Series(sex_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_sex column\n",
    "df['qiita_host_sex'] = normalize_sex(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.3 s ± 466 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit result\n",
    "# 11.3 s ± 466 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This dict was created by searching through all known ethnicity/race columns and compiling all variations of responses\n",
    "\n",
    "ethnicity_dict = {\n",
    "    'white': ['white', 'White' ,'Caucasian', 'caucasian', 'Cauc', 'cauc'],\n",
    "    'black or african american': ['African', 'african', 'Black-African American', 'Afr Am', 'af am'], \n",
    "    'hispanic or latino': ['Hispanic', 'hispanic', 'Latino', 'latino', 'Mestizo', 'Yanomami'], \n",
    "    'asian': ['Asian', 'asian', 'japanese'], \n",
    "    'american indian or alaska native': ['Amerindian', 'nat am', 'nat Aam', 'native.american'], \n",
    "    'native hawaiian or other pacific islander': ['pacific.islander', 'pacific islander', 'Pacific', 'hawaiian'],\n",
    "    'other': ['other', 'Other'],\n",
    "    'multi': ['multi', 'Multi', 'more', 'More']\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ethnicity(df, ethnicity):\n",
    "    '''\n",
    "    normalizes a particular ethnicity based on ethnicity dict above\n",
    "    \n",
    "    param: \n",
    "    - a DataFrame containing all ethnicity/race data\n",
    "    - a string ethnicity to normalize ('ethnicity' must be a key in the above ethnicity dict)\n",
    "    \n",
    "    return: pd.Series containing all normalized, boolean values for the given ethnicity\n",
    "    \n",
    "    '''\n",
    "    ethnicity_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        if type(row['race']) == str:\n",
    "            \n",
    "            # fix to replace caucasian with white\n",
    "            curr = row['race']\n",
    "            if curr == 'Caucasian' or curr == 'caucasian':\n",
    "                curr = 'white' \n",
    "            elif curr == 'Not hispanic or latino':\n",
    "                curr = 'other'\n",
    "\n",
    "            for value in ethnicity_dict[ethnicity]:\n",
    "                if value in curr:\n",
    "                    ethnicity_list.append(True)\n",
    "                    break\n",
    "                elif value == ethnicity_dict[ethnicity][-1]:\n",
    "                    ethnicity_list.append(False)\n",
    "                    \n",
    "        elif type(row['raceethnicity']) == str:\n",
    "                        \n",
    "            # fix to replace caucasian with white\n",
    "            curr = row['raceethnicity']\n",
    "            if curr == 'Caucasian' or curr == 'caucasian':\n",
    "                curr = 'white' \n",
    "            elif curr == 'Not hispanic or latino':\n",
    "                curr = 'other'\n",
    "                \n",
    "            for value in ethnicity_dict[ethnicity]:\n",
    "                if value in curr:\n",
    "                    ethnicity_list.append(True)\n",
    "                    break\n",
    "                elif value == ethnicity_dict[ethnicity][-1]:\n",
    "                    ethnicity_list.append(False)\n",
    "                    \n",
    "        elif type(row['ethnicity']) == str:\n",
    "                        \n",
    "            # fix to replace caucasian with white\n",
    "            curr = row['ethnicity']\n",
    "            if curr == 'Caucasian' or curr == 'caucasian':\n",
    "                curr = 'white' \n",
    "            elif curr == 'Not hispanic or latino':\n",
    "                curr = 'other'\n",
    "                \n",
    "            for value in ethnicity_dict[ethnicity]:\n",
    "                if value in curr:\n",
    "                    ethnicity_list.append(True)\n",
    "                    break\n",
    "                elif value == ethnicity_dict[ethnicity][-1]:\n",
    "                    ethnicity_list.append(False)\n",
    "                    \n",
    "        elif type(row['ethnic_group']) == str:\n",
    "                        \n",
    "            # fix to replace caucasian with white\n",
    "            curr = row['ethnic_group']\n",
    "            if curr == 'Caucasian' or curr == 'caucasian':\n",
    "                curr = 'white' \n",
    "            elif curr == 'Not hispanic or latino':\n",
    "                curr = 'other'\n",
    "                \n",
    "            for value in ethnicity_dict[ethnicity]:\n",
    "                if value in curr:\n",
    "                    ethnicity_list.append(True)\n",
    "                    break\n",
    "                elif value == ethnicity_dict[ethnicity][-1]:\n",
    "                    ethnicity_list.append(False)\n",
    "                    \n",
    "        elif type(row['ethnicgroup']) == str:\n",
    "                        \n",
    "            # fix to replace caucasian with white\n",
    "            curr = row['ethnicgroup']\n",
    "            if curr == 'Caucasian' or curr == 'caucasian':\n",
    "                curr = 'white' \n",
    "            elif curr == 'Not hispanic or latino':\n",
    "                curr = 'other'\n",
    "                \n",
    "            for value in ethnicity_dict[ethnicity]:\n",
    "                if value in curr:\n",
    "                    ethnicity_list.append(True)\n",
    "                    break\n",
    "                elif value == ethnicity_dict[ethnicity][-1]:\n",
    "                    ethnicity_list.append(False)\n",
    "                    \n",
    "        elif type(row['racescrq_self_rpt']) == str:\n",
    "                        \n",
    "            # fix to replace caucasian with white\n",
    "            curr = row['racescrq_self_rpt']\n",
    "            if curr == 'Caucasian' or curr == 'caucasian':\n",
    "                curr = 'white' \n",
    "            elif curr == 'Not hispanic or latino':\n",
    "                curr = 'other'\n",
    "                \n",
    "            for value in ethnicity_dict[ethnicity]:\n",
    "                if value in curr:\n",
    "                    ethnicity_list.append(True)\n",
    "                    break\n",
    "                elif value == ethnicity_dict[ethnicity][-1]:\n",
    "                    ethnicity_list.append(False)\n",
    "                    \n",
    "        elif type(row['ethnicity_scrq_self_rpt']) == str:\n",
    "                        \n",
    "            # fix to replace caucasian with white\n",
    "            curr = row['ethnicity_scrq_self_rpt']\n",
    "            if curr == 'Caucasian' or curr == 'caucasian':\n",
    "                curr = 'white' \n",
    "            elif curr == 'Not hispanic or latino':\n",
    "                curr = 'other'\n",
    "                \n",
    "            for value in ethnicity_dict[ethnicity]:\n",
    "                if value in curr:\n",
    "                    ethnicity_list.append(True)\n",
    "                    break\n",
    "                elif value == ethnicity_dict[ethnicity][-1]:\n",
    "                    ethnicity_list.append(False)\n",
    "\n",
    "        else:\n",
    "            ethnicity_list.append(False)\n",
    "    return pd.Series(ethnicity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_ethnicity columns \n",
    "df['qiita_host_ethnicity_white'] = normalize_ethnicity(df, 'white')\n",
    "df['qiita_host_ethnicity_black_or_african_american'] = normalize_ethnicity(df, 'black or african american')\n",
    "df['qiita_host_ethnicity_hispanic_or_latino'] = normalize_ethnicity(df, 'hispanic or latino')\n",
    "df['qiita_host_ethnicity_asian'] = normalize_ethnicity(df, 'asian')\n",
    "df['qiita_host_ethnicity_american_indian_or_alaska_native'] = normalize_ethnicity(df, 'american indian or alaska native')\n",
    "df['qiita_host_ethnicity_native_hawaiian_or_other_pacific_islander'] = normalize_ethnicity(df, 'native hawaiian or other pacific islander')\n",
    "df['qiita_host_ethnicity_other'] = normalize_ethnicity(df, 'other')\n",
    "df['qiita_host_ethnicity_multiracial'] = normalize_ethnicity(df, 'multi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to determine multiracial \n",
    "def multiracial(df):\n",
    "    '''\n",
    "    looks at previously create qiita_host_ethnicity_[blank] columns to determine whether the host has reported multiple ethnicities/races\n",
    "    \n",
    "    param: DataFrame containing all race/ethnicity data\n",
    "    return: pd.Series containing boolean values of wether the host has multiple races/ethnicities reported\n",
    "    '''\n",
    "    ethnicity_columns = ['qiita_host_ethnicity_white', 'qiita_host_ethnicity_black_or_african_american',\\\n",
    "                         'qiita_host_ethnicity_hispanic_or_latino', 'qiita_host_ethnicity_asian',\\\n",
    "                         'qiita_host_ethnicity_american_indian_or_alaska_native',\\\n",
    "                         'qiita_host_ethnicity_native_hawaiian_or_other_pacific_islander', 'qiita_host_ethnicity_other',\\\n",
    "                         'qiita_host_ethnicity_multiracial']\n",
    "    multiracial_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        multi = False\n",
    "        count = 0\n",
    "        for ethnicity in ethnicity_columns:\n",
    "            if row['qiita_host_ethnicity_multiracial'] == True:\n",
    "                multi = True\n",
    "                break\n",
    "            elif row[ethnicity] == True:\n",
    "                count += 1\n",
    "        if count >= 2 or multi == True:\n",
    "            multiracial_list.append(True)\n",
    "            \n",
    "        else:\n",
    "            multiracial_list.append(False)\n",
    "    return pd.Series(multiracial_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_multiracial column\n",
    "df['qiita_host_multiracial'] = multiracial(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maybe faster way to do this is apply clean_ethnicity_inputs() to entire column/row?\n",
    "\n",
    "# Also how to make clean_ethnicity_inputs so its not hardcoded?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean ethnicity imputs\n",
    "def clean_ethnicity_inputs(entry):\n",
    "    '''\n",
    "    cleans the strings in ethnicity inputs \n",
    "    param: a string entry in an ethnicity column\n",
    "    returns: a normalized string\n",
    "    '''\n",
    "    entry = entry.replace('nA', 'n A')\n",
    "    entry = entry.lower()\n",
    "    entry = entry.replace('half.', '')\n",
    "    entry = entry.replace('.', ' ')\n",
    "    entry = entry.replace('black-', '')\n",
    "    entry = entry.replace('caucasian', 'white')\n",
    "    entry = entry.replace('mestizohispano', 'mestizo')   \n",
    "    entry = entry.replace('amerindian', 'american indian')\n",
    "    return entry   \n",
    "\n",
    "#functions to normalize ethnicity \n",
    "def combined_race(df):\n",
    "    '''\n",
    "    creates a column that has all reported host ethncity/races, cleaned but not normalized at all\n",
    "    eg.) black, japanese, mestizo\n",
    "    \n",
    "    param: dataframe\n",
    "    returns: a pd.Series with merged, but not currated with all ethnicities/races for the given host\n",
    "    '''\n",
    "    ethnicity_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        if type(row['race']) == str:\n",
    "            ethnicity_list.append(clean_ethnicity_inputs(row['race']))\n",
    "        elif type(row['raceethnicity']) == str:\n",
    "            ethnicity_list.append(clean_ethnicity_inputs(row['raceethnicity']))\n",
    "        elif type(row['ethnicity']) == str:\n",
    "            ethnicity_list.append(clean_ethnicity_inputs(row['ethnicity']))\n",
    "        elif type(row['ethnic_group']) == str:\n",
    "            ethnicity_list.append(clean_ethnicity_inputs(row['ethnic_group']))\n",
    "        elif type(row['ethnicgroup']) == str:\n",
    "            ethnicity_list.append(clean_ethnicity_inputs(row['ethnicgroup']))\n",
    "        else:\n",
    "            ethnicity_list.append(float('Nan'))\n",
    "    return pd.Series(ethnicity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_ethnicity column\n",
    "df['qiita_host_ethnicity_combined'] = combined_race(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Weight (in kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to correct weight in kg\n",
    "# Everyone should fall between 0.5kg and 200kg, adults should be at least 20kg\n",
    "def correct_weight(row_index, weight):\n",
    "    '''\n",
    "    cleans & normalizes weight inputs with specified bounds to kilograms\n",
    "    \n",
    "    param: the row of the host and the weight input\n",
    "    return: a cleaned and normalized weight value, or nan if the value is out of bounds\n",
    "    \n",
    "    '''\n",
    "    age = df.iloc[row_index]['qiita_host_age']\n",
    "    \n",
    "    if not math.isnan(float(df.iloc[row_index]['weight'])):\n",
    "        if df.iloc[row_index]['weight_units'] == 'kg':\n",
    "            return round(float(df.iloc[row_index]['weight']), 3)\n",
    "        elif df.iloc[row]['weight_units'] == 'pounds':\n",
    "            return round(float(df.iloc[row_index]['weight']) / 2.205 , 3)\n",
    "                \n",
    "    if weight < 0.5 or weight > 200:\n",
    "        return float('Nan')\n",
    "    if age >= 18:\n",
    "        if weight < 20:\n",
    "            return float('Nan')\n",
    "    else:\n",
    "        return round(float(weight), 3)\n",
    "    return round(float(weight), 3)\n",
    "\n",
    "#function to normalize weight 0.5kg to 200 kg\n",
    "def normalize_weight(df):\n",
    "    '''\n",
    "    imputes cleaned weight values into a pd.Series\n",
    "    \n",
    "    param: DataFrame\n",
    "    return: pd.Series of merged and cleaned values\n",
    "    '''\n",
    "    weight_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        if not math.isnan(float(row['weight'])):\n",
    "            weight = correct_weight(index, float(row['weight']))\n",
    "            weight_list.append(weight)\n",
    "        elif not math.isnan(float(row['weight_kg'])):\n",
    "            weight = correct_weight(index, float(row['weight_kg']))\n",
    "            weight_list.append(weight)\n",
    "        elif not math.isnan(float(row['tot_mass'])):\n",
    "            weight = correct_weight(index, float(row['tot_mass']))\n",
    "            weight_list.append(weight)\n",
    "        else:\n",
    "            weight_list.append(float('Nan'))\n",
    "    return pd.Series(weight_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_weight column\n",
    "df['qiita_host_weight'] = normalize_weight(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_weight_units column\n",
    "weight_units = ['kg']\n",
    "weight_units_list = []\n",
    "\n",
    "for i in range(0, num_row):\n",
    "    weight_units_list += weight_units\n",
    "    \n",
    "df['qiita_host_weight_units'] = pd.Series(weight_units_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Height (in cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to correct height in cm\n",
    "# Everyone should fall between 48cm and 210cm, adults should be at least 105cm\n",
    "def correct_height(row_index, height):\n",
    "    '''\n",
    "    cleans & normalizes height inputs with specified bounds to centimeters\n",
    "    \n",
    "    param: the row of the host and the height input\n",
    "    return: a cleaned and normalized height value, or nan if the value is out of bounds\n",
    "    \n",
    "    '''\n",
    "    age = df.iloc[(row_index)]['qiita_host_age']\n",
    "    if height < 48 or height > 210:\n",
    "        return float('Nan')\n",
    "    if age >= 18:\n",
    "        if height < 20:\n",
    "            return float('Nan')\n",
    "    else:\n",
    "        return round(float(height), 3)\n",
    "    return round(float(height), 3)\n",
    "\n",
    "#function to normalize height\n",
    "def normalize_height(df):\n",
    "    '''\n",
    "    imputes cleaned height values into a pd.Series\n",
    "    \n",
    "    param: DataFrame\n",
    "    return: pd.Series of merged and cleaned values\n",
    "    '''\n",
    "    height_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        if type(row['height']) == str:\n",
    "            height = row['height'].replace(' cm', '')\n",
    "            if not math.isnan(float(height)):\n",
    "                height = correct_height(index, float(height))\n",
    "                height_list.append(height)\n",
    "        elif not math.isnan(float(row['height_cm'])):\n",
    "            height = correct_height(index, float(row['height_cm']))\n",
    "            height_list.append(height)\n",
    "        elif not math.isnan(float(row['height_m'])):\n",
    "            height = correct_height(index, float(row['height_m']) * 100)\n",
    "            height_list.append(height)\n",
    "        elif not math.isnan(float(row['height_or_length'])):\n",
    "            height = correct_height(index, float(row['height_or_length']) * 100)\n",
    "            height_list.append(height)\n",
    "        else:\n",
    "            height_list.append(float('Nan'))\n",
    "    return pd.Series(height_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_height column\n",
    "df['qiita_host_height'] = normalize_height(df)\n",
    "#df['qiita_host_height'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_height_units column\n",
    "height_units = ['cm']\n",
    "height_units_list = []\n",
    "\n",
    "for i in range(0, num_row):\n",
    "    height_units_list += height_units\n",
    "    \n",
    "df['qiita_host_height_units'] = pd.Series(height_units_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to normalize and calculate bmi\n",
    "#organizes bmi values and calculates it for samples with age > 18 w/o bmi\n",
    "#some samples only have bmi categories\n",
    "#corrects by making sure bmi is only between 12 & 42\n",
    "\n",
    "def correct_bmi(bmi):\n",
    "    '''\n",
    "    keeps values within specified BMI bounds\n",
    "    \n",
    "    param: a bmi value\n",
    "    return: a cleaned bmi value, or nan if value is not within bounds\n",
    "    '''\n",
    "    if bmi <= 42 and bmi >= 12:\n",
    "        return round(bmi, 3)\n",
    "    else:\n",
    "        return float('Nan')\n",
    "\n",
    "def normalize_bmi(df):\n",
    "    '''\n",
    "    creates a column of merged and cleaned BMI values\n",
    "    \n",
    "    param: dataframe\n",
    "    returns a series with merged and cleaned BMI values\n",
    "    '''\n",
    "    bmi_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        if not math.isnan(float(row['body_mass_index'])):\n",
    "            curr = correct_bmi(float(row['body_mass_index']))\n",
    "            bmi_list.append(curr)\n",
    "        elif not math.isnan(float(row['bmi_corrected'])):\n",
    "            curr = correct_bmi(float(row['bmi_corrected']))\n",
    "            bmi_list.append(curr)\n",
    "        elif not math.isnan(float(row['bmi'])):\n",
    "            curr = correct_bmi(float(row['bmi']))\n",
    "            bmi_list.append(curr)\n",
    "        #check if has age\n",
    "        elif not math.isnan(float(row['age'])):\n",
    "            #check if >18\n",
    "            if row['qiita_host_age'] >= 18:\n",
    "                #check if has height and weight\n",
    "                if not math.isnan(float(row['qiita_host_height'])) \\\n",
    "                and not math.isnan(float(row['qiita_host_weight'])):\n",
    "                    height = float(row['qiita_host_height']) / 100 # in meters\n",
    "                    weight = float(row['qiita_host_weight']) # in kg\n",
    "                    bmi = correct_bmi(weight / ((height) ** 2))\n",
    "                    bmi_list.append(round(bmi, 3))\n",
    "                else:\n",
    "                    bmi_list.append(float('Nan'))\n",
    "            else:\n",
    "                bmi_list.append(float('Nan'))\n",
    "        else:\n",
    "            bmi_list.append(float('Nan'))\n",
    "    return pd.Series(bmi_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_bmi\n",
    "df['qiita_host_bmi'] = normalize_bmi(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Healthy Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to determine if weight is healthy\n",
    "#add to only check for bmi if age is >=18\n",
    "def healthy_weight(df):\n",
    "    '''\n",
    "    creates boolean values for hosts of healthy weight\n",
    "    \n",
    "    param: dataframe\n",
    "    returns: a column with boolean values, True if host falls within healthy bmi bounds, false otherwise\n",
    "    '''\n",
    "    healthy_weight_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        if row['obesity'] == True:\n",
    "            healthy_weight_list.append(False)\n",
    "        elif float(row['qiita_host_bmi']) >= 18.5 and float(row['qiita_host_bmi']) <= 24.9:\n",
    "            healthy_weight_list.append(True)\n",
    "        elif float(row['qiita_host_bmi']) < 18.5 or float(row['qiita_host_bmi']) > 24.9:\n",
    "            healthy_weight_list.append(False)\n",
    "        else:\n",
    "            healthy_weight_list.append(float('Nan'))\n",
    "    return pd.Series(healthy_weight_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_healthy_weight\n",
    "df['qiita_host_healthy_weight'] = healthy_weight(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['qiita_host_healthy_weight'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Allergies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#food allergies only\n",
    "food_allergy_list = ['peanutallergy', 'shellfishallergy', 'treenutallergy', 'allergic_to_peanuts', 'allergic_to_shellfish',\n",
    "                     'allergic_to_tree_nuts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for normalizing food allergies\n",
    "def normalize_food_allergy(df):\n",
    "    '''\n",
    "    creates a column normalizing food allergies\n",
    "    \n",
    "    param: dataframe\n",
    "    returns: columns with boolean values, True if any food allergies, false otherwise\n",
    "    '''\n",
    "    allergy_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        has_allergy = False\n",
    "\n",
    "        for allergy in food_allergy_list:\n",
    "            if row[allergy] == False:\n",
    "                has_allergy = False\n",
    "            elif row[allergy] == True:\n",
    "                has_allergy = True\n",
    "                #if debug: print(allergy + ':' + str(df.iloc[row][allergy]))\n",
    "                break\n",
    "                \n",
    "        if row['allergic_to_i_have_no_food_allergies_that_i_know_of'] == False:\n",
    "            has_allergy = True\n",
    "\n",
    "        allergy_list.append(has_allergy)\n",
    "    return pd.Series(allergy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_food_allergy column\n",
    "df['qiita_host_food_allergy'] = normalize_food_allergy(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all allergies\n",
    "bool_allergy_list = ['peanutallergy', 'shellfishallergy', 'treenutallergy', 'allergic_contact_dermatitis', \n",
    "        'allergic_rhinitis_', 'allergic_to_other', \n",
    "        'allergic_to_peanuts', 'allergic_to_shellfish', 'allergic_to_tree_nuts', 'allergic_to_unspecified', 'beestingallergies', 'drugallergies', \n",
    "        'non_food_allergies_beestings', 'non_food_allergies_drug_eg_penicillin', 'non_food_allergies_pet_dander', \n",
    "        'non_food_allergies_poison_ivyoak', 'non_food_allergies_sun', 'non_food_allergies_unspecified',  \n",
    "        'poisonivyoakallergies', 'seasonal_allergies', 'seasonalallergies', 'sunallergies']\n",
    "str_allergy_list = ['otherallergies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for normalize allergies\n",
    "def normalize_allergy(df):\n",
    "    '''\n",
    "    creates a column normalizing allergies\n",
    "    \n",
    "    param: dataframe\n",
    "    returns: columns with boolean values, True if any allergies, false otherwise\n",
    "    '''\n",
    "    allergy_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        has_allergy = False\n",
    "\n",
    "        for allergy in bool_allergy_list:\n",
    "            if row[allergy] == False:\n",
    "                has_allergy = False\n",
    "            elif row[allergy] == True:\n",
    "                has_allergy = True\n",
    "                #if debug: print(allergy + ':' + str(df.iloc[row][allergy]))\n",
    "                break\n",
    "                \n",
    "        if row['allergic_to_i_have_no_food_allergies_that_i_know_of'] == False:\n",
    "            has_allergy = True\n",
    "\n",
    "        if has_allergy != True:\n",
    "            for str_allergy in str_allergy_list:\n",
    "                temp = df[str_allergy].fillna('not provided')\n",
    "                if temp[index] == 'no' or temp[index] == 'not provided':\n",
    "                    has_allergy = False\n",
    "                else:\n",
    "                    has_allergy = True\n",
    "                    break\n",
    "        allergy_list.append(has_allergy)\n",
    "    return pd.Series(allergy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_allergy\n",
    "df['qiita_host_allergy'] = normalize_allergy(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Cancers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_list = ['bladder_cancer', 'brain_cancer', 'breast_cancer',\n",
    "       'cervical_cancer', 'colon_cancer', 'melanoma', 'non_hodgkin_lymphoma',\n",
    "       'endometrial_cancer', 'kidney_cancer', 'lung_cancer', 'leukemia',\n",
    "       'non_melanoma_skin_cancer', 'ovarian_cancer', 'pancreatic_cancer',\n",
    "       'prostate_cancer', 'rectal_cancer', 'stomach_cancer', 'thyroid_cancer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to normalize cancer\n",
    "def normalize_cancer(df):\n",
    "    '''\n",
    "    creates a column normalizing cancer\n",
    "    \n",
    "    param: dataframe\n",
    "    returns: columns with boolean values, True if any cancers, false otherwise\n",
    "    '''\n",
    "    result_list = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        has_cancer = False\n",
    "\n",
    "        for cancer in cancer_list:\n",
    "            if row[cancer] == True:\n",
    "                has_cancer = True\n",
    "                break\n",
    "        if row['cancer'] == 'Diagnosed by a medical professional (doctor, physician assistant)':\n",
    "            has_cancer = True\n",
    "        result_list.append(has_cancer)\n",
    "        \n",
    "    return pd.Series(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_cancer column\n",
    "df['qiita_host_cancer'] = normalize_cancer(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize IBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT INCLUDE 'subset_ibd'\n",
    "ibd_dict = {'ibd': ['Colitis', 'Yes.IBS', 'Crohns', 'Diagnosed by a medical professional (doctor, physician assistant)'], \n",
    "            'ibd_diagnosis': ['Ulcerative colitis', \"Crohn's disease\"] , \n",
    "            'ibd_diagnosis_refined': ['Ulcerative colitis', \"Colonic Crohn's Disease\", 'Microcolitis'], \n",
    "            'gastrointest_disord': ['CD', \"Crohn's  Disease\", 'UC', \"Crohn's Disease\", 'IC'],\n",
    "           'ulcerative_colitis': [True],\n",
    "            'crohns_disease': [True]\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to normalize ibd\n",
    "def normalize_ibd(df):\n",
    "    '''\n",
    "    creates a column normalizing irritable bowel disease\n",
    "    \n",
    "    param: dataframe\n",
    "    returns: columns with boolean values, True if ibd, false otherwise\n",
    "    '''\n",
    "    ibd_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        has_ibd = False\n",
    "        for column in ibd_dict:\n",
    "            temp = df[column].fillna('not provided')\n",
    "            if temp[index] in ibd_dict[column]:\n",
    "                has_ibd = True\n",
    "                break\n",
    "        ibd_list.append(has_ibd)\n",
    "    return pd.Series(ibd_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_ibd column\n",
    "df['qiita_host_ibd'] = normalize_ibd(df)\n",
    "#df['qiita_host_ibd'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibd_true_count = 0\n",
    "ibd_false_count = 0\n",
    "for row in range(0, num_row):\n",
    "    if df.iloc[row]['qiita_host_ibd'] == True:\n",
    "        if df.iloc[row]['qiita_study_id'] == 10317:\n",
    "            ibd_true_count += 1\n",
    "    elif df.iloc[row]['qiita_host_ibd'] == False:\n",
    "        if df.iloc[row]['qiita_study_id'] == 10317:\n",
    "            ibd_false_count += 1\n",
    "#print('true:', ibd_true_count)\n",
    "#print('false: ', ibd_false_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_ibd_type\n",
    "def ibd_subtype(df):\n",
    "    '''\n",
    "    creates a column specifying ibd subtypes\n",
    "    \n",
    "    param: dataframe\n",
    "    return: a column specifying the specific types of ibd (uc, ic, not specified, or not applicable)\n",
    "    '''\n",
    "    subtypes = []\n",
    "    for index, row in df.iterrows():\n",
    "        if row['crohns_disease'] == True:\n",
    "            subtypes.append('cd')\n",
    "        elif row['ulcerative_colitis'] == True:\n",
    "            subtypes.append('uc')\n",
    "        elif row['ibd'] == 'Colitis':\n",
    "            subtypes.append('uc')\n",
    "        elif row['ibd'] == 'Crohns':\n",
    "            subtypes.append('cd')\n",
    "        elif row['ibd_diagnosis'] == 'Ulcerative colitis':\n",
    "            subtypes.append('uc')\n",
    "        elif row['ibd_diagnosis'] == \"Crohn's disease\":\n",
    "            subtypes.append('cd')\n",
    "        elif row['ibd_diagnosis_refined'] == 'Ulcerative colitis':\n",
    "            subtypes.append('uc')\n",
    "        elif row['ibd_diagnosis_refined'] == \"Colonic Crohn's Disease\":\n",
    "            subtypes.append('cd')\n",
    "        elif row['gastrointest_disord'] == 'CD' or row['gastrointest_disord'] == 'UC' or row['gastrointest_disord'] == 'IC':\n",
    "            subtypes.append(row['gastrointest_disord'].lower())\n",
    "        elif row['gastrointest_disord'] == \"Crohn's  Disease\" or row['gastrointest_disord'] == \"Crohn's Disease\":\n",
    "            subtypes.append('cd')\n",
    "        elif row['qiita_host_ibd'] == True:\n",
    "            subtypes.append('not specified')\n",
    "        else:\n",
    "            subtypes.append('not applicable')\n",
    "    return pd.Series(subtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_ibd_type\n",
    "df['qiita_host_ibd_type'] = ibd_subtype(df)\n",
    "#df['qiita_host_ibd_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_count = 0\n",
    "ns_count = 0\n",
    "uc_count = 0\n",
    "cd_count = 0\n",
    "for row in range(0, num_row):\n",
    "    if df.iloc[row]['qiita_host_ibd_type'] == 'not applicable':\n",
    "        if df.iloc[row]['qiita_study_id'] == 10317:\n",
    "            na_count += 1\n",
    "    elif df.iloc[row]['qiita_host_ibd_type'] == 'not specified':\n",
    "        if df.iloc[row]['qiita_study_id'] == 10317:\n",
    "            ns_count += 1\n",
    "    elif df.iloc[row]['qiita_host_ibd_type'] == 'uc':\n",
    "        if df.iloc[row]['qiita_study_id'] == 10317:\n",
    "            uc_count += 1\n",
    "    elif df.iloc[row]['qiita_host_ibd_type'] == 'cd':\n",
    "        if df.iloc[row]['qiita_study_id'] == 10317:\n",
    "            cd_count += 1\n",
    "#print('not applicable: ', na_count)\n",
    "#print('not specified: ', ns_count)\n",
    "#print('uc: ', uc_count)\n",
    "#print('cd: ', cd_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT INCLUDE 'subset_diabetes'\n",
    "diabetes_dict = {'diabetes' : ['yes.type.I', 'Diagnosed by a medical professional (doctor, physician assistant)', 'true'], \n",
    "                 'diabetes_mellitustype_1' : [True], \n",
    "                 'diabetes_mellitustype_2' : [True],\n",
    "                 'diabetes_type' : ['Type II diabetes']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to normalize diabetes\n",
    "def normalize_diabetes(df):\n",
    "    '''\n",
    "    creates a columns with boolean values for diabetes\n",
    "    \n",
    "    param: dataframe\n",
    "    return: column wtih boolean values, true if host has diabetes, false otherwise\n",
    "    '''\n",
    "    diabetes_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        has_diabetes = False\n",
    "        for column in diabetes_dict:\n",
    "            temp = df[column].fillna('not provided')\n",
    "            if temp[index] in diabetes_dict[column]:\n",
    "                has_diabetes = True\n",
    "                break\n",
    "        diabetes_list.append(has_diabetes)\n",
    "    return pd.Series(diabetes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_diabetes column\n",
    "df['qiita_host_diabetes'] = normalize_diabetes(df)\n",
    "df['qiita_host_diabetes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_count = 0\n",
    "false_count = 0\n",
    "for row in range(0, num_row):\n",
    "    if df.iloc[row]['qiita_host_diabetes'] == True and df.iloc[row]['qiita_study_id'] == 10317:\n",
    "        true_count += 1\n",
    "    elif df.iloc[row]['qiita_host_diabetes'] == False and df.iloc[row]['qiita_study_id'] == 10317:\n",
    "        false_count += 1\n",
    "print('true:', true_count)\n",
    "print('false: ', false_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_diabetes_subtype\n",
    "def diabetes_subtype(df):\n",
    "    '''\n",
    "    creates a column specifying types of diabetes\n",
    "    \n",
    "    param: dataframe\n",
    "    returns: a column with specific diabetes types (type1, type2, no type, not applicable)\n",
    "    '''\n",
    "    subtypes = []\n",
    "    for index, row in df.iterrows():\n",
    "        if row['diabetes_mellitustype_1'] == True:\n",
    "            subtypes.append('type1')\n",
    "        elif row['diabetes_mellitustype_2'] == True:\n",
    "            subtypes.append('type2')\n",
    "        elif row['diabetes'] == 'yes.type.I':\n",
    "            subtypes.append('type1')\n",
    "        elif row['diabetes_type'] == 'Type II diabetes':\n",
    "            subtypes.append('type2')\n",
    "        elif row['qiita_host_diabetes'] == True:\n",
    "            subtypes.append('no type')\n",
    "        else:\n",
    "            subtypes.append('not applicable')\n",
    "    return pd.Series(subtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_diabetes_subtype\n",
    "df['qiita_host_diabetes_subtype'] = diabetes_subtype(df)\n",
    "#df['qiita_host_diabetes_subtype'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_count = 0\n",
    "ns_count = 0\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "for row in range(0, num_row):\n",
    "    if df.iloc[row]['qiita_host_diabetes_subtype'] == 'not applicable':\n",
    "        if df.iloc[row]['qiita_study_id'] == 10317:\n",
    "            na_count += 1\n",
    "    elif df.iloc[row]['qiita_host_diabetes_subtype'] == 'no type':\n",
    "        if df.iloc[row]['qiita_study_id'] == 10317:\n",
    "            ns_count += 1\n",
    "    elif df.iloc[row]['qiita_host_diabetes_subtype'] == 'type1':\n",
    "        if df.iloc[row]['qiita_study_id'] == 10317:\n",
    "            count1 += 1\n",
    "    elif df.iloc[row]['qiita_host_diabetes_subtype'] == 'type2':\n",
    "        if df.iloc[row]['qiita_study_id'] == 10317:\n",
    "            count2 += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('not applicable: ', na_count)\n",
    "#print('not specified: ', ns_count)\n",
    "#print('type1: ', count1)\n",
    "#print('type2: ', count2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Miscellaneous Diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_values =[True, 'True','true','yes','y','Yes','Y','YES', 'Diagnosed by a medical professional (doctor, physician assistant)']\n",
    "false_values = [False, 'False','false', 'no', 'n', 'No', 'N', 'NO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_dict = {'cardiovascular_disease': [True], 'celiac_disease': [True],\n",
    "       'chronicliverdisease_cirrhosis': [True], 'chronicobstructivepulm_disease': [True],\n",
    "       'disease': ['sinusproblems_candida', 'asthma_allergictopepper', 'sinusproblems', 'asthma', 'asthma_dermatitis',\n",
    "                    'thyroidhealthproblems', 'allergictopenicillin_fibromyalgia'], \n",
    "        'disease_stat': ['hypertension', 'allercic asthma', 'acid reflux', 'gastric heartburn_episodic',\n",
    "                        'hypertension_acid reflux', 'acid reflux_episodic', 'hypertriglyceridemia',\n",
    "                        'hypertension_dyslipidemia', 'diabetes', 'cholesterol', 'gastritis',\n",
    "                         'ischemic cardiopathy_metabolic syndrome', 'liver steatosis_hypertransaminasemia',\n",
    "                            'hypertransaminasemia'],\n",
    "       'fibrocystic_breast_disease': [True], 'gastroesophagealreflux_disease': [True],\n",
    "       'graves_disease': [True], 'hirschsprungs_disease': [True], 'huntingtons_disease': [True],\n",
    "       'kawasaki_disease': [True], 'kidney_disease': [True], 'liver_disease': [True], 'lung_disease': [True],\n",
    "       'menieres_disease': [True], 'nonalcoholicfattyliver_disease': [True],\n",
    "       'osgood_schlatter_disease': [True], 'parkinsons_disease': [True], 'peyronies_disease': [True],\n",
    "       'polycystic_kidney_disease': [True],\n",
    "       'von_willebrand_disease': [True], 'acne': true_values, 'acute_kidney_failure': true_values, 'acute_liver_failure': true_values,\n",
    "       'age_related_cataract': true_values, 'age_related_hearing_loss': true_values, 'age_related_macular_degen': true_values,\n",
    "       'alopecia_areata': true_values, 'alzheimers': true_values, 'amyotrophic_lateral_sclerosis_': true_values, 'angina': true_values, \n",
    "       'aortic_aneurysm': true_values, 'appendicitis': true_values, 'asd': true_values, 'asthma': true_values, 'atherosclerosis': true_values, \n",
    "       'atrial_fibrillation': true_values, 'autoimmune_hemolytic_anemia': true_values, 'barretts_esophagus': true_values, \n",
    "       'bartholins_cyst': true_values, 'bells_palsy': true_values, 'cdiff': true_values, 'cdiff_positive_yn': true_values, 'chickenpox': true_values,\n",
    "       'chronic_bronchitis': true_values, 'chronic_kidney_failure': true_values, 'chronic_recurrent_tonsillitis': true_values,\n",
    "       'chronic_sinusitis': true_values, 'chronicliverdisease_cirrhosis': true_values, 'chronicobstructivepulm_disease': true_values,\n",
    "       'colon_polyps': true_values, 'congestive_heart_failure': true_values, 'cystic_fibrosis': true_values, 'dandruff': true_values, \n",
    "       'deep_vein_thrombosis': true_values, 'depression_bipolar_schizophrenia': true_values, 'dermatographia': true_values, \n",
    "       'dilated_cardiomyopathy':true_values, 'diverticulosis': true_values, 'eczema': true_values, 'emphysema': true_values, 'endometriosis': true_values, \n",
    "       'epilepsy': true_values, 'epilepsy_or_seizure_disorder': true_values, 'fibromyalgia': true_values, 'gallstones': true_values, \n",
    "       'gbs': [], 'gilbert_syndrome': true_values, 'hemochromatosis': true_values, 'hemorrhoids': true_values, 'hiv': true_values, \n",
    "                'ibs': ['Diagnosed by a medical professional (doctor, physician assistant)'],\n",
    "                'irrit_bowel_syndrome': true_values, 'perianal_disease': true_values,\n",
    "       'irritable_bowel_syndrome_': true_values, 'mental_illness': true_values, 'mental_illness_type_anorexia_nervosa': true_values, \n",
    "       'mental_illness_type_bipolar_disorder': true_values, 'mental_illness_type_bulimia_nervosa': true_values, \n",
    "       'mental_illness_type_depression': true_values, 'mental_illness_type_ptsd_posttraumatic_stress_disorder': true_values, \n",
    "       'mental_illness_type_schizophrenia': true_values, 'mental_illness_type_substance_abuse': true_values,\n",
    "       'mental_illness_type_unspecified': true_values, 'long_qt_syndrome': true_values, 'malaria': true_values, 'ovarian_cysts': true_values, \n",
    "       'patientdied': true_values, 'polycystic_kidney_disease': true_values, 'polycystic_ovary_syndrome_': true_values, 'sickle_cell_anemia': true_values, \n",
    "       'sjogrens_syndrome_': true_values, 'urethral_diverticulum': true_values,'urinary_tract_infection_': true_values, \n",
    "                'wolff_parkinson_white_syndrome': true_values, \n",
    "               'ss_constipation': true_values, 'p3m_constipation': true_values, 'ss_excess_gas': true_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to normalize disease\n",
    "def normalize_disease(df):\n",
    "    '''\n",
    "    creates a boolean column for general diseases\n",
    "    \n",
    "    param: dataframe\n",
    "    return: a column with True if any of the above specified columns are true, false otherwise\n",
    "    '''\n",
    "    disease_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        has_disease = False\n",
    "        for column in disease_dict:\n",
    "            temp = df[column].fillna('not provided')\n",
    "            if temp[index] in disease_dict[column]:\n",
    "                has_disease = True\n",
    "                break\n",
    "        disease_list.append(has_disease)\n",
    "    return pd.Series(disease_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_disease column\n",
    "df['qiita_host_disease'] = normalize_disease(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Medication Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_dict = {'antibiotic': true_values, 'antibiotic_1': ['7_28_AB_for_tooth_extraction', 'Azithromycin_8_30_-_9_3_10_Bronchitis', 'bactrim_skiunknownbscess_7_16_2010_-_7_20_2010'],\n",
    "            'antibiotic_disturbance': true_values,\n",
    "       'antibiotic_history': true_values, 'antibiotics': true_values, 'antibiotics_after_birth': true_values,\n",
    "       'antibiotics_at_birth': true_values, 'antibiotics_past_6_months': true_values, 'antibiotic_select': ['Year', '6 months',\n",
    "        'Years', 'Month'], \n",
    "            'drug_usage': ['TRUE','Ibuprofen','birth control','Claritin','allergy medication','antacids','Prilosec',\n",
    "                           'Ortho Tri-cyclen Lo','Tums, Advil','Prevacid','Lamictal, lithium carb',\n",
    "                           'DayQuil','Zantec, Tums, Zertec','Cephalexin','Propecia','OrthoNovum',\n",
    "                           'Septra, Zofran, chemotherapy drugs','Aleve, Claritin','Levothyroxine',\n",
    "                           'Ambien','thyroid hormone','Gaviscon','Nasonex',\n",
    "                           'baby aspirin, Omerprazole, Isosorbride, Lisinopril, Lovastatin, Plavix, Altenolol, Klosnopin, Neurontin, Requip,Finasteride, Acyclovir, Xanax, Nitroglycercin','Zicam, OrthoTriCyclinLo','Tylenol, Oragel','Nuvaring','Fluocinonide cream (eczema)','Omeprazole','baby aspirin, Lipitor, Diovan HCT','albuterol inhaler','Prilosec, Simuastatin, Diazide, Atenolol, Hydroxyzine, Claritan','Evista, Fosamax, Prilosec','Lisinopril, Simvastatin, Hydrochilorol','Actonel','Klonopin, Prozac, Immipramine, Warfarin, Cozaar, Tenex, Calan',\n",
    "                           'Benadryl','Advil, Benadryl','colace','Equate, Azor, Hydrocholothiazide, aspirin, Nexium',\n",
    "                           'baby aspirin, Zantac','Advil','baby aspirin, beta-blockers, statins, ace inhibitors','Advil, Lyrica'], \n",
    "       'idantibioticdisturbance': true_values, 'p3m_antibiotics': ['|azithromycin|', '|Ciprofloxacin|', '|amoxicillin|',\n",
    "    '|doxycycline|', '|Augmentin|' , '|Z-PACK|', '|doxycycline|amoxicillin|', '|cephalexin|', '|standard|', '|Leviquin|',\n",
    "    '|fluconazole|', '|besivance|', '|Flagyl|Ciprofloxacin|', '|amox tr-k clv|', '|keflex|', '|Biaxin|amoxicillin|', '|Rocephin|', \n",
    "    '|Niprofurantoin|Ciprofloxacin|', '|nystatin|', '|Ampicillin|'],\n",
    "       'sampleantibioticdisturbance': true_values, 'subset_antibiotic_history': false_values, 'acne_medication': true_values, \n",
    "            'acne_medication_otc': true_values,\n",
    "       'other_medications': true_values, 'othermedication': true_values, 'drug_usage': true_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to normalize medication use\n",
    "def normalize_medication(df):\n",
    "    '''\n",
    "    creates a boolean column for medication use\n",
    "    \n",
    "    param: a dataframe\n",
    "    return: a column of boolean values, True if host used medication, false otherwise\n",
    "    '''\n",
    "    med_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        med = False\n",
    "        for column in med_dict:\n",
    "            temp = df[column].fillna('not provided')\n",
    "            if temp[index] in med_dict[column]:\n",
    "                med = True\n",
    "                break\n",
    "        med_list.append(med)\n",
    "    return pd.Series(med_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_medication column\n",
    "df['qiita_host_medication'] = normalize_medication(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Host Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_columns = ['qiita_host_disease', 'qiita_host_diabetes', 'qiita_host_ibd', 'qiita_host_cancer', 'qiita_host_food_allergy',\n",
    "                  'qiita_host_healthy_weight', 'qiita_host_medication']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to normalize healthy\n",
    "def normalize_healthy(df):\n",
    "    '''\n",
    "    creates a boolean column for a general \"healthy\" host\n",
    "    \n",
    "    param: a dataframe\n",
    "    return: a boolean column , true if host is healthy and false otherwise\n",
    "    '''\n",
    "    healthy_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        healthy = True\n",
    "        for disease in disease_columns:\n",
    "            if row[disease] == True:\n",
    "                healthy = False\n",
    "                break\n",
    "        healthy_list.append(healthy)\n",
    "    return pd.Series(healthy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_healthy\n",
    "df['qiita_host_healthy'] = normalize_healthy(df)\n",
    "df['qiita_host_healthy'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Body Site and Body Habitat Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Body Site Normalization Process:\n",
    "    1. Take all columns containing body site info by searching for 'body' and/or 'site'\n",
    "    2. Take all body sites inputs and clean string values\n",
    "    3. Apply to all rows\n",
    "   \n",
    "Body Habitat Normalization Process:\n",
    "    1. Take all body habitats by searching through all columns with key words\n",
    "    2. Take all body habitat inputs and clean string values\n",
    "    3. Take all body site values and give body habitat if none inputted\n",
    "    4. Apply to all rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#SampleID</th>\n",
       "      <th>aborh</th>\n",
       "      <th>achilles_tendinitis</th>\n",
       "      <th>acid_reflux</th>\n",
       "      <th>acne</th>\n",
       "      <th>acne_medication</th>\n",
       "      <th>acne_medication_otc</th>\n",
       "      <th>active_disease</th>\n",
       "      <th>activity_target</th>\n",
       "      <th>acute_kidney_failure</th>\n",
       "      <th>...</th>\n",
       "      <th>years_known_subject</th>\n",
       "      <th>years_smoker</th>\n",
       "      <th>yellow_rice_wine</th>\n",
       "      <th>ygrt</th>\n",
       "      <th>ygrt_freq</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>yogurt_brand</th>\n",
       "      <th>yogurt_live_culture</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>zygosity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8961</th>\n",
       "      <td>10317.000047627.61479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I do not have this condition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39624</th>\n",
       "      <td>10317.000041666.57180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I do not have this condition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38947</th>\n",
       "      <td>10317.000036420.60418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31723</th>\n",
       "      <td>10352.MIC20270251.57838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33168</th>\n",
       "      <td>10564.FPEBR7P4.61987</td>\n",
       "      <td>AB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2570 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     #SampleID aborh achilles_tendinitis  \\\n",
       "8961     10317.000047627.61479   NaN                 NaN   \n",
       "39624    10317.000041666.57180   NaN                 NaN   \n",
       "38947    10317.000036420.60418   NaN                 NaN   \n",
       "31723  10352.MIC20270251.57838   NaN                 NaN   \n",
       "33168     10564.FPEBR7P4.61987   AB                  NaN   \n",
       "\n",
       "                        acid_reflux acne acne_medication acne_medication_otc  \\\n",
       "8961   I do not have this condition  NaN           False               False   \n",
       "39624  I do not have this condition  NaN           False               False   \n",
       "38947                           NaN  NaN           False               False   \n",
       "31723                           NaN  NaN             NaN                 NaN   \n",
       "33168                           NaN  NaN             NaN                 NaN   \n",
       "\n",
       "      active_disease activity_target acute_kidney_failure   ...     \\\n",
       "8961             NaN             NaN                  NaN   ...      \n",
       "39624            NaN             NaN                  NaN   ...      \n",
       "38947            NaN             NaN                  NaN   ...      \n",
       "31723            NaN             NaN                  NaN   ...      \n",
       "33168            NaN             NaN                  NaN   ...      \n",
       "\n",
       "      years_known_subject years_smoker yellow_rice_wine ygrt ygrt_freq yogurt  \\\n",
       "8961                  NaN          NaN              NaN  NaN       NaN    NaN   \n",
       "39624                 NaN          NaN              NaN  NaN       NaN    NaN   \n",
       "38947                 NaN          NaN              NaN  NaN       NaN    NaN   \n",
       "31723                 NaN          NaN              NaN  NaN       NaN    NaN   \n",
       "33168                 NaN          NaN              NaN  NaN       NaN    NaN   \n",
       "\n",
       "      yogurt_brand yogurt_live_culture zipcode zygosity  \n",
       "8961           NaN                 NaN     NaN      NaN  \n",
       "39624          NaN                 NaN     NaN      NaN  \n",
       "38947          NaN                 NaN     NaN      NaN  \n",
       "31723          NaN                 NaN     NaN      NaN  \n",
       "33168          NaN                 NaN     NaN      NaN  \n",
       "\n",
       "[5 rows x 2570 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df.sample(frac=0.25, replace=False)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_body_site(df):\n",
    "    '''\n",
    "    normalize body sites\n",
    "    \n",
    "    param: df\n",
    "    returns: series\n",
    "    '''\n",
    "    body_sites = ['bodysite_oralmucosa_forehead_volarright_palmright_footright_vag', \n",
    "            'host_body_product', 'host_body_site', 'simple_body_site','common_sample_site', 'hmp_site',\n",
    "            'superbodysiteoralskinunknownsevaginaanalsaureola', 'title_body_site', 'site_sampled', 'body_site']\n",
    "    \n",
    "    def clean_body_site(string):\n",
    "        #once you know the granularity of the body sites, you can add just more to this function to finish\n",
    "        string = string.replace('UBERON:', '')\n",
    "        string = string.replace('ICU-FECAL', 'feces')\n",
    "        string = string.replace('Stool', 'feces')\n",
    "        string = string.replace('FECAL', 'feces')\n",
    "        return string\n",
    "    \n",
    "    def find_body_site(row):\n",
    "        for col in body_sites:\n",
    "            if not pd.isna(row[col]):\n",
    "                return clean_body_site(row[col])\n",
    "        return np.nan\n",
    "    \n",
    "    result = pd.Series()\n",
    "    result = df.apply(find_body_site, axis = 1) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['qiita_host_body_site'] = normalize_body_site(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feces              36870\n",
       "ileum                641\n",
       "rectum               309\n",
       "large intestine      184\n",
       "colon                 77\n",
       "cecum                 48\n",
       "Feces                  8\n",
       "SKBTI089               1\n",
       "Name: qiita_host_body_site, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['qiita_host_body_site'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['body_habitat', 'host_body_habitat', 'qiita_host_body_habitat'], dtype='object')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contains('body_habitat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UBERON:feces                      23420\n",
       "UBERON:gastrointestinal system     1075\n",
       "intestine                           184\n",
       "feces                               115\n",
       "Name: body_habitat, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.body_habitat.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_body_habitats(df):\n",
    "    '''\n",
    "    normalize body habitats\n",
    "    \n",
    "    param: df\n",
    "    returns: series\n",
    "    '''\n",
    "    body_habitats = ['body_habitat', 'host_body_habitat']\n",
    "    \n",
    "    def clean_body_habitat(string):\n",
    "        #once you know the granularity of the body habitats, you can add just more to this function to finish\n",
    "        string = string.replace('UBERON:', '')\n",
    "        string = string.replace('gastrointestinal system', 'gi tract')\n",
    "        string = string.replace('intestine', 'gi tract')\n",
    "        string = string.lower()\n",
    "        return string\n",
    "    \n",
    "    def find_body_habitat(row):\n",
    "        for col in body_habitats:\n",
    "            if not pd.isna(row[col]):\n",
    "                return clean_body_habitat(row[col])\n",
    "            elif not pd.isna(row['qiita_host_body_site']):\n",
    "                if row['qiita_host_body_site'] == 'feces':\n",
    "                    return 'feces'\n",
    "                else:\n",
    "                    return 'gi tract'\n",
    "        return np.nan\n",
    "    \n",
    "    result = df.apply(find_body_habitat, axis = 1) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['qiita_host_body_habitat'] = normalize_body_habitats(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feces       36879\n",
       "gi tract     1259\n",
       "Name: qiita_host_body_habitat, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['qiita_host_body_habitat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#SampleID</th>\n",
       "      <th>aborh</th>\n",
       "      <th>achilles_tendinitis</th>\n",
       "      <th>acid_reflux</th>\n",
       "      <th>acne</th>\n",
       "      <th>acne_medication</th>\n",
       "      <th>acne_medication_otc</th>\n",
       "      <th>active_disease</th>\n",
       "      <th>activity_target</th>\n",
       "      <th>acute_kidney_failure</th>\n",
       "      <th>...</th>\n",
       "      <th>ygrt</th>\n",
       "      <th>ygrt_freq</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>yogurt_brand</th>\n",
       "      <th>yogurt_live_culture</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>zygosity</th>\n",
       "      <th>qiita_host_bosy_site</th>\n",
       "      <th>qiita_host_body_site</th>\n",
       "      <th>qiita_host_body_habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11669.St.chronic.GLD019.T.60388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feces</td>\n",
       "      <td>feces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10352.MIC20100111.57838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feces</td>\n",
       "      <td>feces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11405.subject631.timepoint0.60671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10317.000022608.56754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feces</td>\n",
       "      <td>feces</td>\n",
       "      <td>feces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11358.2353.61922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>feces</td>\n",
       "      <td>feces</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2573 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           #SampleID aborh achilles_tendinitis acid_reflux  \\\n",
       "0    11669.St.chronic.GLD019.T.60388   NaN                 NaN         NaN   \n",
       "1            10352.MIC20100111.57838   NaN                 NaN         NaN   \n",
       "2  11405.subject631.timepoint0.60671   NaN                 NaN         NaN   \n",
       "3              10317.000022608.56754   NaN                 NaN         NaN   \n",
       "4                   11358.2353.61922   NaN                 NaN         NaN   \n",
       "\n",
       "  acne acne_medication acne_medication_otc active_disease activity_target  \\\n",
       "0  NaN             NaN                 NaN            NaN             NaN   \n",
       "1  NaN             NaN                 NaN            NaN             NaN   \n",
       "2  NaN             NaN                 NaN            NaN             NaN   \n",
       "3  NaN            True               False            NaN             NaN   \n",
       "4  NaN             NaN                 NaN            NaN             NaN   \n",
       "\n",
       "  acute_kidney_failure           ...           ygrt ygrt_freq yogurt  \\\n",
       "0                  NaN           ...            NaN       NaN    NaN   \n",
       "1                  NaN           ...            NaN       NaN    NaN   \n",
       "2                  NaN           ...            NaN       NaN    NaN   \n",
       "3                  NaN           ...            NaN       NaN    NaN   \n",
       "4                  NaN           ...            NaN       NaN    NaN   \n",
       "\n",
       "  yogurt_brand yogurt_live_culture zipcode zygosity qiita_host_bosy_site  \\\n",
       "0          NaN                 NaN     NaN      NaN                  NaN   \n",
       "1          NaN                 NaN     NaN      NaN                  NaN   \n",
       "2          NaN                 NaN     NaN      NaN                  NaN   \n",
       "3          NaN                 NaN     NaN      NaN                feces   \n",
       "4          NaN                 NaN     NaN      NaN                  NaN   \n",
       "\n",
       "  qiita_host_body_site qiita_host_body_habitat  \n",
       "0                feces                   feces  \n",
       "1                feces                   feces  \n",
       "2                  NaN                     NaN  \n",
       "3                feces                   feces  \n",
       "4                feces                   feces  \n",
       "\n",
       "[5 rows x 2573 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atherosclerosis Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atherosclerosis(df):\n",
    "    def merge_as(row):\n",
    "        if row['atherosclerosis'] == True:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    result = df.apply(merge_as, axis = 1)\n",
    "    return result        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['qiita_host_atherosclerosis'] = atherosclerosis(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    40591\n",
       "True       172\n",
       "Name: qiita_host_atherosclerosis, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['qiita_host_atherosclerosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arthritis Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arthritis(df):\n",
    "    types = ['osteoarthritis', 'rheumatoid_arthritis']\n",
    "    def find_body_site(row):\n",
    "        for col in types:\n",
    "            if row[col] == True:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    result = df.apply(find_body_site, axis = 1) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['qiita_host_arthritis'] = arthritis(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    40210\n",
       "True       553\n",
       "Name: qiita_host_arthritis, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['qiita_host_arthritis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alzheimer's Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['alzheimers', 'alzheimers_dementia', 'alzheimers_dementia_aao'], dtype='object')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contains('lzheimer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                                                                  27443\n",
       "I do not have this condition                                         13289\n",
       "Diagnosed by a medical professional (doctor, physician assistant)       22\n",
       "Self-diagnosed                                                           6\n",
       "Diagnosed by an alternative medicine practitioner                        3\n",
       "Name: alzheimers, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.alzheimers.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alzheimers(df):\n",
    "    cols = ['alzheimers', 'alzheimers_dementia']\n",
    "    def find_body_site(row):\n",
    "        for col in cols:\n",
    "            if row[col] == True or row[col] == 'Diagnosed by a medical professional (doctor, physician assistant)':\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    result = df.apply(find_body_site, axis = 1) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['qiita_host_alzheimers'] = alzheimers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    40730\n",
       "True        33\n",
       "Name: qiita_host_alzheimers, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['qiita_host_alzheimers'] = alzheimers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN      40450\n",
       "False      302\n",
       "True        11\n",
       "Name: alzheimers_dementia, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.alzheimers_dementia.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN      40754\n",
       " 65.0        2\n",
       " 81.0        2\n",
       " 68.0        1\n",
       " 73.0        1\n",
       " 80.0        1\n",
       " 72.0        1\n",
       " 64.0        1\n",
       "Name: alzheimers_dementia_aao, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.alzheimers_dementia_aao.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_sample_type column\n",
    "sample_type = ['stool']\n",
    "sample_type_list = []\n",
    "\n",
    "for i in range(0, num_row):\n",
    "    sample_type_list += sample_type\n",
    "    \n",
    "df['qiita_host_sample_type'] = pd.Series(sample_type_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_empo_1 column \n",
    "empo_1 = ['host_associated']\n",
    "empo_1_list = []\n",
    "\n",
    "for i in range(0, num_row):\n",
    "    empo_1_list += empo_1\n",
    "    \n",
    "df['qiita_empo_1'] = pd.Series(empo_1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_empo_2 column \n",
    "empo_2 = ['animal']\n",
    "empo_2_list = []\n",
    "\n",
    "for i in range(0, num_row):\n",
    "    empo_2_list += empo_2\n",
    "    \n",
    "df['qiita_empo_2'] = pd.Series(empo_2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_empo_3 column \n",
    "empo_3 = ['animal distal gut']\n",
    "empo_3_list = []\n",
    "\n",
    "for i in range(0, num_row):\n",
    "    empo_3_list += empo_3\n",
    "    \n",
    "df['qiita_empo_3'] = pd.Series(empo_3_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_scientific_name column \n",
    "scientific_name = ['Homo sapiens']\n",
    "scientific_name_list = []\n",
    "\n",
    "for i in range(0, num_row):\n",
    "    scientific_name_list += scientific_name\n",
    "    \n",
    "df['qiita_host_scientific_name'] = pd.Series(scientific_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_taxid column \n",
    "taxid = [9606]\n",
    "taxid_list = []\n",
    "\n",
    "for i in range(0, num_row):\n",
    "    taxid_list += taxid\n",
    "    \n",
    "df['qiita_host_taxid'] = pd.Series(taxid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_host_common_name column\n",
    "common_name = ['human']\n",
    "common_name_list = []\n",
    "\n",
    "for i in range(0, num_row):\n",
    "    common_name_list += common_name\n",
    "    \n",
    "df['qiita_host_common_name'] = pd.Series(common_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiita_env_feature column\n",
    "env_feature = ['human-associated habitat']\n",
    "env_feature_list = []\n",
    "\n",
    "for i in range(0, num_row):\n",
    "    env_feature_list += env_feature\n",
    "    \n",
    "df['qiita_env_feature'] = pd.Series(env_feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('#SampleID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('fecal_03_08_19.tsv', sep = '\\t', na_rep = 'not provided', index = False)\n",
    "df.to_csv('fecal_03_08_19.csv', sep = ',', na_rep = 'not provided', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
